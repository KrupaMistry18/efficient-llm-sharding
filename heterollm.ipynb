{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPL5LTA+jBERCoq6579/eJ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrupaMistry18/efficient-llm-sharding/blob/main/heterollm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9TKDzwMC6Z9",
        "outputId": "af721a03-ee15-40b3-efb4-ad404cfce576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 | Torch: 2.8.0+cu126 | CUDA: 12.6\n",
            "GPU available: True\n",
            "GPU name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch, platform, sys, subprocess, os\n",
        "print(\"Python:\", sys.version.split()[0], \"| Torch:\", torch.__version__, \"| CUDA:\", torch.version.cuda)\n",
        "print(\"GPU available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU? In Colab: Runtime → Change runtime type → Hardware accelerator = GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers datasets accelerate matplotlib rich tabulate\n",
        "# Torch is preinstalled on Colab; we don’t need DeepSpeed/FairScale for this prototype.\n"
      ],
      "metadata": {
        "id": "uPW2pmCCC_WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pathlib\n",
        "for p in [\"src\", \"scripts\", \"results\", \"data\", \"notebooks\"]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "open(\"src/__init__.py\",\"w\").close()\n",
        "open(\"scripts/__init__.py\",\"w\").close()\n",
        "print(\"Folders ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c6HxmZZC_JW",
        "outputId": "d1be8cba-1c64-4772-e46e-700f0e7d5e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/model_loader.py\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "def load_gpt2_small():\n",
        "    # Downloads the first time; cached afterwards\n",
        "    model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "    return model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNVaXzrMDWZW",
        "outputId": "b38c5e6a-02f3-4afc-da47-36ff3003a31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/model_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/mapping.py\n",
        "from typing import List, Dict\n",
        "\n",
        "def uniform_mapping(n_blocks: int, devices: List[str]) -> Dict[int, str]:\n",
        "    \"\"\"Evenly assign blocks across devices in order.\"\"\"\n",
        "    assert len(devices) >= 1\n",
        "    if len(devices) == 1:\n",
        "        return {i: devices[0] for i in range(n_blocks)}\n",
        "    per = n_blocks // len(devices)\n",
        "    rem = n_blocks % len(devices)\n",
        "    mapping = {}\n",
        "    idx = 0\n",
        "    for d_i, d in enumerate(devices):\n",
        "        take = per + (1 if d_i < rem else 0)\n",
        "        for _ in range(take):\n",
        "            mapping[idx] = d\n",
        "            idx += 1\n",
        "    return mapping\n",
        "\n",
        "def hetero_mapping_by_speed(n_blocks: int, devices: List[str], rel_speed: List[float]) -> Dict[int, str]:\n",
        "    \"\"\"Assign blocks proportional to device relative speeds, e.g., rel_speed=[2.0, 1.0].\"\"\"\n",
        "    assert len(devices) == len(rel_speed) and len(devices) >= 1\n",
        "    total = sum(rel_speed)\n",
        "    target = [round(n_blocks * (s / total)) for s in rel_speed]\n",
        "\n",
        "    # adjust rounding so sum == n_blocks\n",
        "    diff = n_blocks - sum(target)\n",
        "    order = sorted(range(len(devices)), key=lambda i: rel_speed[i], reverse=True)\n",
        "    k = 0\n",
        "    while diff != 0:\n",
        "        i = order[k % len(order)]\n",
        "        target[i] += 1 if diff > 0 else -1\n",
        "        diff += -1 if diff > 0 else 1\n",
        "        k += 1\n",
        "\n",
        "    mapping = {}\n",
        "    idx = 0\n",
        "    for i, d in enumerate(devices):\n",
        "        for _ in range(target[i]):\n",
        "            mapping[idx] = d\n",
        "            idx += 1\n",
        "    return mapping\n",
        "\n",
        "def mapping_by_costs(costs: List[float], devices: List[str], rel_speed: List[float]) -> Dict[int, str]:\n",
        "    \"\"\"\n",
        "    Assign blocks using measured per-block costs.\n",
        "    Target device cost share is proportional to rel_speed.\n",
        "    Greedy: fill fastest device up to its target first.\n",
        "    \"\"\"\n",
        "    assert len(devices) == len(rel_speed) >= 1\n",
        "    n = len(costs)\n",
        "    total_cost = sum(costs)\n",
        "    speed_sum = sum(rel_speed)\n",
        "    targets = [total_cost * (s / speed_sum) for s in rel_speed]\n",
        "\n",
        "    order = sorted(range(len(devices)), key=lambda i: rel_speed[i], reverse=True)\n",
        "    mapping = {}\n",
        "    used = [False] * n\n",
        "\n",
        "    for di in order:\n",
        "        cap = targets[di]\n",
        "        cur = 0.0\n",
        "        for bi in sorted(range(n), key=lambda j: costs[j], reverse=True):\n",
        "            if used[bi]:\n",
        "                continue\n",
        "            if cur + costs[bi] <= cap or di == order[-1]:  # last device gets the rest\n",
        "                mapping[bi] = devices[di]\n",
        "                used[bi] = True\n",
        "                cur += costs[bi]\n",
        "\n",
        "    # any unassigned -> slowest\n",
        "    slowest = order[-1]\n",
        "    for bi in range(n):\n",
        "        if bi not in mapping:\n",
        "            mapping[bi] = devices[slowest]\n",
        "\n",
        "    return {i: mapping[i] for i in range(n)}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cwkGkb0DWPQ",
        "outputId": "3bff0a1e-6178-49d7-a9b0-e3130a298ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/mapping.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/profiling.py\n",
        "import time, torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def profile_block_forward_times(model, seq_len=256, batch_size=4, iters=3, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Returns a list of per-block forward times (seconds) measured on `device`.\n",
        "    Uses synthetic inputs so it’s fast and self-contained.\n",
        "    \"\"\"\n",
        "    model.eval().to(device)\n",
        "\n",
        "    vocab = model.config.vocab_size\n",
        "    input_ids = torch.randint(0, vocab, (batch_size, seq_len), device=device)\n",
        "    attn = torch.ones_like(input_ids, dtype=torch.bool)[:, None, None, :]  # [B,1,1,S] bool\n",
        "\n",
        "    pos = torch.arange(0, seq_len, device=device).unsqueeze(0)\n",
        "    hs = model.transformer.wte(input_ids) + model.transformer.wpe(pos)\n",
        "\n",
        "    # warmup a couple small blocks\n",
        "    for _ in range(1):\n",
        "        tmp = hs\n",
        "        for blk in model.transformer.h[:2]:\n",
        "            tmp = blk(tmp, attention_mask=attn)[0]\n",
        "\n",
        "    times = []\n",
        "    for blk in model.transformer.h:\n",
        "        tmp = hs.clone()\n",
        "        t0 = time.time()\n",
        "        for _ in range(iters):\n",
        "            tmp = blk(tmp, attention_mask=attn)[0]\n",
        "        t1 = time.time()\n",
        "        times.append((t1 - t0) / iters)\n",
        "\n",
        "    return times\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhGDWAzoDcjy",
        "outputId": "6989902a-d676-4a5e-f35b-e1e4a8ac0caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/profiling.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/sharded_module.py\n",
        "import torch\n",
        "from torch import nn\n",
        "from typing import Dict\n",
        "\n",
        "class GPT2Sharded(nn.Module):\n",
        "    \"\"\"\n",
        "    Minimal sharder for GPT-2: places specified transformer blocks on target devices\n",
        "    and routes hidden states across them.\n",
        "    \"\"\"\n",
        "    def __init__(self, model: nn.Module, block_to_device: Dict[int, str]):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.block_to_device = dict(block_to_device)\n",
        "\n",
        "        # Start on block 0's device\n",
        "        first_dev = torch.device(self.block_to_device[0])\n",
        "\n",
        "        # Keep tied weights on the SAME device (wte <-> lm_head), and ln_f with them\n",
        "        self.model.transformer.wte.to(first_dev)\n",
        "        self.model.transformer.wpe.to(first_dev)\n",
        "        self.model.transformer.ln_f.to(first_dev)\n",
        "        self.model.lm_head.to(first_dev)\n",
        "\n",
        "        # Place transformer blocks where requested\n",
        "        for i, blk in enumerate(self.model.transformer.h):\n",
        "            blk.to(torch.device(self.block_to_device[i]))\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        dev0 = torch.device(self.block_to_device[0])\n",
        "\n",
        "        # Embeddings on dev0\n",
        "        input_ids = input_ids.to(dev0)\n",
        "        pos = torch.arange(0, input_ids.shape[1], device=dev0).unsqueeze(0)\n",
        "        hidden_states = self.model.transformer.wte(input_ids) + self.model.transformer.wpe(pos)\n",
        "\n",
        "        # Key-padding mask: [B,1,1,S], bool\n",
        "        attn_expanded = None\n",
        "        if attention_mask is not None:\n",
        "            attn_expanded = attention_mask\n",
        "            if attn_expanded.dtype is not torch.bool:\n",
        "                attn_expanded = attn_expanded != 0\n",
        "            attn_expanded = attn_expanded.to(dev0)[:, None, None, :]\n",
        "\n",
        "        # Route through blocks\n",
        "        for i, blk in enumerate(self.model.transformer.h):\n",
        "            blk_dev = torch.device(self.block_to_device[i])\n",
        "            if hidden_states.device != blk_dev:\n",
        "                hidden_states = hidden_states.to(blk_dev)\n",
        "            am = attn_expanded.to(blk_dev) if attn_expanded is not None else None\n",
        "            hidden_states = blk(hidden_states, attention_mask=am)[0]\n",
        "\n",
        "        # Move back to dev0 for ln_f + lm_head\n",
        "        if hidden_states.device != dev0:\n",
        "            hidden_states = hidden_states.to(dev0)\n",
        "        logits = self.model.lm_head(self.model.transformer.ln_f(hidden_states))\n",
        "        return logits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5Ji24_oDcco",
        "outputId": "6c12abdc-f094-4909-e18e-116f5e5fe789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/sharded_module.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/train_eval.py\n",
        "import time, torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from .model_loader import load_gpt2_small\n",
        "from .sharded_module import GPT2Sharded\n",
        "from .mapping import uniform_mapping, hetero_mapping_by_speed, mapping_by_costs\n",
        "from .profiling import profile_block_forward_times\n",
        "\n",
        "def detect_devices():\n",
        "    \"\"\"\n",
        "    On Colab, prefer single-device emulation to remove transfer noise.\n",
        "    If multiple CUDA GPUs exist, we can use two; otherwise we emulate both shards on cuda:0.\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        n = torch.cuda.device_count()\n",
        "        if n >= 2:\n",
        "            return [f\"cuda:0\", f\"cuda:1\"]\n",
        "        return [\"cuda:0\"]\n",
        "    return [\"cpu\"]\n",
        "\n",
        "@torch.no_grad()\n",
        "def benchmark(mode: str = \"both\", samples: int = 256, seq_len: int = 256, batch_size: int = 4, rel_speed=(2.0, 1.0)):\n",
        "    tok = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "    if tok.pad_token is None:\n",
        "        tok.pad_token = tok.eos_token\n",
        "\n",
        "    # synthetic, fast, reproducible\n",
        "    input_ids = torch.randint(low=0, high=tok.vocab_size, size=(samples, seq_len))\n",
        "    attn_mask = torch.ones_like(input_ids, dtype=torch.bool)\n",
        "\n",
        "    dl = DataLoader(TensorDataset(input_ids, attn_mask), batch_size=batch_size, shuffle=False)\n",
        "    base_model = load_gpt2_small().eval()\n",
        "    n_blocks = len(base_model.transformer.h)\n",
        "\n",
        "    devices = detect_devices()\n",
        "    emulate_slow = False\n",
        "    if len(devices) == 1:\n",
        "        devices = [devices[0], devices[0]]  # both logical shards on same physical device\n",
        "        emulate_slow = True\n",
        "    fast_dev, slow_dev = devices[0], devices[1]\n",
        "\n",
        "    if mode == \"uniform\":\n",
        "        block_map = uniform_mapping(n_blocks, [fast_dev, slow_dev])\n",
        "        return _run_eval(base_model, dl, block_map, fast_dev, slow_dev, emulate_slow=emulate_slow)\n",
        "    elif mode == \"hetero\":\n",
        "        block_map = hetero_mapping_by_speed(n_blocks, [fast_dev, slow_dev], list(rel_speed))\n",
        "        return _run_eval(base_model, dl, block_map, fast_dev, slow_dev, emulate_slow=emulate_slow)\n",
        "    elif mode == \"hetero_profiled\":\n",
        "        # 1) profile costs on the fast device\n",
        "        costs = profile_block_forward_times(base_model, seq_len=seq_len, batch_size=batch_size, iters=3, device=fast_dev)\n",
        "        # 2) derive mapping based on measured cost & relative speeds\n",
        "        block_map = mapping_by_costs(costs, [fast_dev, slow_dev], list(rel_speed))\n",
        "        return _run_eval(base_model, dl, block_map, fast_dev, slow_dev, emulate_slow=emulate_slow)\n",
        "    elif mode == \"both\":\n",
        "        uni_map = uniform_mapping(n_blocks, [fast_dev, slow_dev])\n",
        "        het_map = hetero_mapping_by_speed(n_blocks, [fast_dev, slow_dev], list(rel_speed))\n",
        "        uni_res = _run_eval(base_model, dl, uni_map, fast_dev, slow_dev, emulate_slow=emulate_slow)\n",
        "        het_res = _run_eval(base_model, dl, het_map, fast_dev, slow_dev, emulate_slow=emulate_slow)\n",
        "        return {\"uniform\": uni_res, \"hetero\": het_res}\n",
        "    else:\n",
        "        raise ValueError(\"mode must be one of: uniform | hetero | hetero_profiled | both\")\n",
        "\n",
        "def _run_eval(base_model, dl, block_map, fast_dev, slow_dev, emulate_slow=False):\n",
        "    model = GPT2Sharded(base_model, block_map).eval()\n",
        "    total_tokens = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    for input_ids, attn_mask in dl:\n",
        "        if emulate_slow:\n",
        "            import time as _t\n",
        "            slow_blocks = sum(1 for _, d in block_map.items() if d == slow_dev)\n",
        "            _t.sleep(0.001 * slow_blocks)  # tune factor for clearer separation\n",
        "\n",
        "        _ = model(input_ids, attn_mask)\n",
        "        total_tokens += input_ids.numel()\n",
        "\n",
        "    elapsed = time.time() - t0\n",
        "    tps = total_tokens / max(elapsed, 1e-6)\n",
        "    return {\n",
        "        \"devices\": {\"fast\": fast_dev, \"slow\": slow_dev},\n",
        "        \"blocks_on_fast\": sum(1 for _, d in block_map.items() if d == fast_dev),\n",
        "        \"blocks_on_slow\": sum(1 for _, d in block_map.items() if d == slow_dev),\n",
        "        \"elapsed_sec\": elapsed,\n",
        "        \"tokens\": total_tokens,\n",
        "        \"tokens_per_sec\": tps,\n",
        "    }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcS3DxWDDcDR",
        "outputId": "75f48973-753b-4ef9-c3fc-f0ea3d34c430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/train_eval.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scripts/run_benchmark.py\n",
        "# path patch for running as a script\n",
        "import os, sys\n",
        "ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
        "if ROOT not in sys.path:\n",
        "    sys.path.insert(0, ROOT)\n",
        "\n",
        "import argparse, json\n",
        "from src.train_eval import benchmark\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--mode\", type=str, default=\"both\",\n",
        "                    choices=[\"uniform\", \"hetero\", \"hetero_profiled\", \"both\"])\n",
        "    ap.add_argument(\"--samples\", type=int, default=256)\n",
        "    ap.add_argument(\"--seq-len\", type=int, default=256)\n",
        "    ap.add_argument(\"--batch-size\", type=int, default=4)\n",
        "    ap.add_argument(\"--rel-speed\", type=float, nargs=2, default=[2.0, 1.0],\n",
        "                    help=\"Relative speed fast:slow\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    res = benchmark(\n",
        "        mode=args.mode,\n",
        "        samples=args.samples,\n",
        "        seq_len=args.seq_len,\n",
        "        batch_size=args.batch_size,\n",
        "        rel_speed=args.rel_speed,\n",
        "    )\n",
        "    print(json.dumps(res, indent=2))\n",
        "\n",
        "    # save\n",
        "    import time, pathlib\n",
        "    pathlib.Path(\"results\").mkdir(exist_ok=True, parents=True)\n",
        "    fname = os.path.join(\"results\", f\"bench_{args.mode}_{int(time.time())}.json\")\n",
        "    with open(fname, \"w\") as f:\n",
        "        json.dump(res, f, indent=2)\n",
        "    print(\"Saved:\", fname)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06fCFiTWDhjH",
        "outputId": "41c2a303-3c96-4bde-fb8e-36b582e9a664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scripts/run_benchmark.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scripts/plot_results.py\n",
        "import argparse, json, os, glob\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_results(paths):\n",
        "    records = []\n",
        "    for p in paths:\n",
        "        try:\n",
        "            with open(p, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "            if \"tokens_per_sec\" in data:\n",
        "                mode = \"unknown\"\n",
        "                bn = os.path.basename(p)\n",
        "                if \"uniform\" in bn: mode = \"uniform\"\n",
        "                if \"hetero_profiled\" in bn: mode = \"hetero_profiled\"\n",
        "                elif \"hetero\" in bn: mode = \"hetero\"\n",
        "                records.append({\"path\": p, \"mode\": mode, **data})\n",
        "            else:\n",
        "                for k, v in data.items():\n",
        "                    records.append({\"path\": p, \"mode\": k, **v})\n",
        "        except Exception as e:\n",
        "            print(\"skip\", p, e)\n",
        "    return records\n",
        "\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"results_dir\", type=str, nargs=\"?\", default=\"results\")\n",
        "    ap.add_argument(\"--out\", type=str, default=None,\n",
        "                    help=\"Custom output PNG name (optional)\")\n",
        "    ap.add_argument(\"--modes\", type=str, nargs=\"*\", default=None,\n",
        "                    help=\"Filter by modes (e.g., uniform hetero hetero_profiled)\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    files = glob.glob(os.path.join(args.results_dir, \"bench_*.json\"))\n",
        "    if not files:\n",
        "        print(\"No results found.\")\n",
        "        return\n",
        "\n",
        "    recs = load_results(files)\n",
        "\n",
        "    # keep only latest per mode\n",
        "    latest_by_mode = {}\n",
        "    for r in sorted(recs, key=lambda x: os.path.getmtime(x[\"path\"])):\n",
        "        latest_by_mode[r[\"mode\"]] = r\n",
        "    recs = list(latest_by_mode.values())\n",
        "\n",
        "    if args.modes:\n",
        "        recs = [r for r in recs if r[\"mode\"] in args.modes]\n",
        "\n",
        "    modes = [r[\"mode\"] for r in recs]\n",
        "    tps = [r[\"tokens_per_sec\"] for r in recs]\n",
        "\n",
        "    print(\"\\nLatest results:\")\n",
        "    for r in recs:\n",
        "        print(f\"- {r['mode']:15s} | tokens/s: {r['tokens_per_sec']:.2f}\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.bar(modes, tps)\n",
        "    plt.title(\"Tokens/sec by sharding mode\")\n",
        "    plt.xlabel(\"Mode\")\n",
        "    plt.ylabel(\"Tokens/sec\")\n",
        "\n",
        "    if args.out:\n",
        "        out_png = args.out\n",
        "    else:\n",
        "        ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        out_png = os.path.join(args.results_dir, f\"tps_{'-'.join(modes)}_{ts}.png\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_png, dpi=200)\n",
        "    print(\"Saved:\", out_png)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBSI5c8gDheP",
        "outputId": "a241545b-9c4d-429b-a124-87018927d457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scripts/plot_results.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/run_benchmark.py --mode both --samples 256 --seq-len 256\n",
        "!python scripts/plot_results.py results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGtE2FbiDhW0",
        "outputId": "e1cd7d92-ee76-49a5-b301-3d4b746b3cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-15 19:57:29.001716: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763236649.019166    3910 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763236649.024094    3910 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763236649.038821    3910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763236649.038845    3910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763236649.038849    3910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763236649.038854    3910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 19:57:29.043427: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"uniform\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 4.722888708114624,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 13876.253295445946\n",
            "  },\n",
            "  \"hetero\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 4.646709680557251,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 14103.74318718803\n",
            "  }\n",
            "}\n",
            "Saved: results/bench_both_1763236664.json\n",
            "\n",
            "Latest results:\n",
            "- uniform         | tokens/s: 13876.25\n",
            "- hetero          | tokens/s: 14103.74\n",
            "Saved: results/tps_uniform-hetero_20251115-195747.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/run_benchmark.py --mode hetero_profiled --samples 256 --seq-len 256\n",
        "!python scripts/plot_results.py results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze_99mtODy2e",
        "outputId": "b0b25411-f983-4e64-e877-623a56d5b0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-15 19:58:04.664496: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763236684.681825    4076 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763236684.686649    4076 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763236684.701311    4076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763236684.701339    4076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763236684.701343    4076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763236684.701348    4076 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 19:58:04.705773: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"devices\": {\n",
            "    \"fast\": \"cuda:0\",\n",
            "    \"slow\": \"cuda:0\"\n",
            "  },\n",
            "  \"blocks_on_fast\": 12,\n",
            "  \"blocks_on_slow\": 12,\n",
            "  \"elapsed_sec\": 4.80034065246582,\n",
            "  \"tokens\": 65536,\n",
            "  \"tokens_per_sec\": 13652.36443508144\n",
            "}\n",
            "Saved: results/bench_hetero_profiled_1763236695.json\n",
            "\n",
            "Latest results:\n",
            "- uniform         | tokens/s: 13876.25\n",
            "- hetero          | tokens/s: 14103.74\n",
            "- hetero_profiled | tokens/s: 13652.36\n",
            "Saved: results/tps_uniform-hetero-hetero_profiled_20251115-195818.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/plot_results.py results --modes uniform hetero hetero_profiled --out results/tps_all_modes.png\n"
      ],
      "metadata": {
        "id": "ZLhNWPZ3Dyq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebe3084-f4a4-48e4-b4b3-63745c1b3401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Latest results:\n",
            "- uniform         | tokens/s: 13876.25\n",
            "- hetero          | tokens/s: 14103.74\n",
            "- hetero_profiled | tokens/s: 13652.36\n",
            "Saved: results/tps_all_modes.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uniform vs Hetero (N trials)\n",
        "N = 5\n",
        "for _ in range(N):\n",
        "    !python scripts/run_benchmark.py --mode both --samples 256 --seq-len 256\n",
        "\n",
        "# Profile-driven (N trials)\n",
        "for _ in range(N):\n",
        "    !python scripts/run_benchmark.py --mode hetero_profiled --samples 256 --seq-len 256\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmEohXUtHSzj",
        "outputId": "d8c50828-c311-4ace-d2dc-96b8f60beb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-15 20:03:11.052746: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763236991.071178    5349 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763236991.076298    5349 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763236991.091199    5349 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763236991.091231    5349 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763236991.091235    5349 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763236991.091238    5349 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 20:03:11.095760: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"uniform\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 4.752119064331055,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 13790.900251617613\n",
            "  },\n",
            "  \"hetero\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 4.6348676681518555,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 14139.778024370728\n",
            "  }\n",
            "}\n",
            "Saved: results/bench_both_1763237006.json\n",
            "2025-11-15 20:03:34.214328: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763237014.231732    5460 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763237014.236627    5460 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763237014.250849    5460 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237014.250883    5460 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237014.250889    5460 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237014.250893    5460 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 20:03:34.255437: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"uniform\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 4.793660640716553,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 13671.389134922936\n",
            "  },\n",
            "  \"hetero\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 4.732867479324341,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 13846.996622300494\n",
            "  }\n",
            "}\n",
            "Saved: results/bench_both_1763237029.json\n",
            "2025-11-15 20:03:57.522020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763237037.539236    5571 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763237037.544154    5571 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763237037.558875    5571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237037.558900    5571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237037.558904    5571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237037.558907    5571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 20:03:57.563352: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"uniform\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 4.9076087474823,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 13353.957777017426\n",
            "  },\n",
            "  \"hetero\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 4.814100503921509,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 13613.342709944496\n",
            "  }\n",
            "}\n",
            "Saved: results/bench_both_1763237052.json\n",
            "2025-11-15 20:04:21.103378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763237061.120812    5680 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763237061.125670    5680 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763237061.139796    5680 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237061.139823    5680 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237061.139827    5680 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237061.139832    5680 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 20:04:21.144181: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"uniform\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 4.933223724365234,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 13284.619482452646\n",
            "  },\n",
            "  \"hetero\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 4.8896002769470215,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 13403.140602102449\n",
            "  }\n",
            "}\n",
            "Saved: results/bench_both_1763237076.json\n",
            "2025-11-15 20:04:44.587891: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763237084.605343    5793 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763237084.610171    5793 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763237084.625450    5793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237084.625475    5793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237084.625479    5793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237084.625482    5793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 20:04:44.630148: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"uniform\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 5.045496225357056,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 12989.009816445201\n",
            "  },\n",
            "  \"hetero\": {\n",
            "    \"devices\": {\n",
            "      \"fast\": \"cuda:0\",\n",
            "      \"slow\": \"cuda:0\"\n",
            "    },\n",
            "    \"blocks_on_fast\": 12,\n",
            "    \"blocks_on_slow\": 12,\n",
            "    \"elapsed_sec\": 5.0171959400177,\n",
            "    \"tokens\": 65536,\n",
            "    \"tokens_per_sec\": 13062.27637578946\n",
            "  }\n",
            "}\n",
            "Saved: results/bench_both_1763237100.json\n",
            "2025-11-15 20:05:08.435603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763237108.456045    5902 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763237108.461044    5902 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763237108.478995    5902 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237108.479022    5902 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237108.479027    5902 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237108.479031    5902 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 20:05:08.483302: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"devices\": {\n",
            "    \"fast\": \"cuda:0\",\n",
            "    \"slow\": \"cuda:0\"\n",
            "  },\n",
            "  \"blocks_on_fast\": 12,\n",
            "  \"blocks_on_slow\": 12,\n",
            "  \"elapsed_sec\": 5.208967924118042,\n",
            "  \"tokens\": 65536,\n",
            "  \"tokens_per_sec\": 12581.379066774778\n",
            "}\n",
            "Saved: results/bench_hetero_profiled_1763237119.json\n",
            "2025-11-15 20:05:26.787057: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763237126.804664    5995 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763237126.809783    5995 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763237126.824190    5995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237126.824217    5995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237126.824221    5995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237126.824224    5995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 20:05:26.828636: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"devices\": {\n",
            "    \"fast\": \"cuda:0\",\n",
            "    \"slow\": \"cuda:0\"\n",
            "  },\n",
            "  \"blocks_on_fast\": 12,\n",
            "  \"blocks_on_slow\": 12,\n",
            "  \"elapsed_sec\": 5.231259822845459,\n",
            "  \"tokens\": 65536,\n",
            "  \"tokens_per_sec\": 12527.766201517545\n",
            "}\n",
            "Saved: results/bench_hetero_profiled_1763237138.json\n",
            "2025-11-15 20:05:46.551840: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763237146.569140    6088 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763237146.574095    6088 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763237146.588426    6088 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237146.588452    6088 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237146.588456    6088 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237146.588460    6088 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 20:05:46.592847: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"devices\": {\n",
            "    \"fast\": \"cuda:0\",\n",
            "    \"slow\": \"cuda:0\"\n",
            "  },\n",
            "  \"blocks_on_fast\": 12,\n",
            "  \"blocks_on_slow\": 12,\n",
            "  \"elapsed_sec\": 5.2472662925720215,\n",
            "  \"tokens\": 65536,\n",
            "  \"tokens_per_sec\": 12489.551005401063\n",
            "}\n",
            "Saved: results/bench_hetero_profiled_1763237157.json\n",
            "2025-11-15 20:06:04.965787: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763237164.983244    6179 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763237164.988199    6179 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763237165.003219    6179 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237165.003246    6179 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237165.003252    6179 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237165.003255    6179 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 20:06:05.007702: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"devices\": {\n",
            "    \"fast\": \"cuda:0\",\n",
            "    \"slow\": \"cuda:0\"\n",
            "  },\n",
            "  \"blocks_on_fast\": 12,\n",
            "  \"blocks_on_slow\": 12,\n",
            "  \"elapsed_sec\": 5.280812501907349,\n",
            "  \"tokens\": 65536,\n",
            "  \"tokens_per_sec\": 12410.211492328008\n",
            "}\n",
            "Saved: results/bench_hetero_profiled_1763237176.json\n",
            "2025-11-15 20:06:24.735360: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763237184.752308    6274 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763237184.757096    6274 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763237184.771512    6274 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237184.771539    6274 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237184.771544    6274 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763237184.771548    6274 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 20:06:24.775858: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{\n",
            "  \"devices\": {\n",
            "    \"fast\": \"cuda:0\",\n",
            "    \"slow\": \"cuda:0\"\n",
            "  },\n",
            "  \"blocks_on_fast\": 12,\n",
            "  \"blocks_on_slow\": 12,\n",
            "  \"elapsed_sec\": 5.3107922077178955,\n",
            "  \"tokens\": 65536,\n",
            "  \"tokens_per_sec\": 12340.15518527725\n",
            "}\n",
            "Saved: results/bench_hetero_profiled_1763237195.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os, glob, pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "def flatten_json(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    # single-mode file\n",
        "    if \"tokens_per_sec\" in data:\n",
        "        return [{\n",
        "            \"mode\": (\"hetero_profiled\" if \"hetero_profiled\" in os.path.basename(path)\n",
        "                     else \"hetero\" if \"hetero\" in os.path.basename(path)\n",
        "                     else \"uniform\"),\n",
        "            \"tokens_per_sec\": data[\"tokens_per_sec\"],\n",
        "            \"elapsed_sec\": data[\"elapsed_sec\"],\n",
        "            \"blocks_fast\": data[\"blocks_on_fast\"],\n",
        "            \"blocks_slow\": data[\"blocks_on_slow\"],\n",
        "            \"devices\": str(data[\"devices\"]),\n",
        "            \"file\": os.path.basename(path),\n",
        "            \"ts\": datetime.fromtimestamp(os.path.getmtime(path))\n",
        "        }]\n",
        "    # both-mode file\n",
        "    rows = []\n",
        "    for m, v in data.items():\n",
        "        rows.append({\n",
        "            \"mode\": m,\n",
        "            \"tokens_per_sec\": v[\"tokens_per_sec\"],\n",
        "            \"elapsed_sec\": v[\"elapsed_sec\"],\n",
        "            \"blocks_fast\": v[\"blocks_on_fast\"],\n",
        "            \"blocks_slow\": v[\"blocks_on_slow\"],\n",
        "            \"devices\": str(v[\"devices\"]),\n",
        "            \"file\": os.path.basename(path),\n",
        "            \"ts\": datetime.fromtimestamp(os.path.getmtime(path))\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "files = glob.glob(\"results/bench_*.json\")\n",
        "rows = []\n",
        "for p in files:\n",
        "    rows.extend(flatten_json(p))\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"ts\")\n",
        "df.to_csv(\"results/summary_all_runs.csv\", index=False)\n",
        "print(\"Saved: results/summary_all_runs.csv\")\n",
        "df.tail(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "5Af7o9EQIMKK",
        "outputId": "f83de719-6709-4233-e070-107c135668a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: results/summary_all_runs.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               mode  tokens_per_sec  elapsed_sec  blocks_fast  blocks_slow  \\\n",
              "4           uniform    13353.957777     4.907609           12           12   \n",
              "9           uniform    13284.619482     4.933224           12           12   \n",
              "10           hetero    13403.140602     4.889600           12           12   \n",
              "3            hetero    13062.276376     5.017196           12           12   \n",
              "2           uniform    12989.009816     5.045496           12           12   \n",
              "8   hetero_profiled    12581.379067     5.208968           12           12   \n",
              "12  hetero_profiled    12527.766202     5.231260           12           12   \n",
              "14  hetero_profiled    12489.551005     5.247266           12           12   \n",
              "13  hetero_profiled    12410.211492     5.280813           12           12   \n",
              "11  hetero_profiled    12340.155185     5.310792           12           12   \n",
              "\n",
              "                                 devices  \\\n",
              "4   {'fast': 'cuda:0', 'slow': 'cuda:0'}   \n",
              "9   {'fast': 'cuda:0', 'slow': 'cuda:0'}   \n",
              "10  {'fast': 'cuda:0', 'slow': 'cuda:0'}   \n",
              "3   {'fast': 'cuda:0', 'slow': 'cuda:0'}   \n",
              "2   {'fast': 'cuda:0', 'slow': 'cuda:0'}   \n",
              "8   {'fast': 'cuda:0', 'slow': 'cuda:0'}   \n",
              "12  {'fast': 'cuda:0', 'slow': 'cuda:0'}   \n",
              "14  {'fast': 'cuda:0', 'slow': 'cuda:0'}   \n",
              "13  {'fast': 'cuda:0', 'slow': 'cuda:0'}   \n",
              "11  {'fast': 'cuda:0', 'slow': 'cuda:0'}   \n",
              "\n",
              "                                     file                         ts  \n",
              "4              bench_both_1763237052.json 2025-11-15 20:04:12.917347  \n",
              "9              bench_both_1763237076.json 2025-11-15 20:04:36.536093  \n",
              "10             bench_both_1763237076.json 2025-11-15 20:04:36.536093  \n",
              "3              bench_both_1763237100.json 2025-11-15 20:05:00.361854  \n",
              "2              bench_both_1763237100.json 2025-11-15 20:05:00.361854  \n",
              "8   bench_hetero_profiled_1763237119.json 2025-11-15 20:05:19.412265  \n",
              "12  bench_hetero_profiled_1763237138.json 2025-11-15 20:05:38.435676  \n",
              "14  bench_hetero_profiled_1763237157.json 2025-11-15 20:05:57.567094  \n",
              "13  bench_hetero_profiled_1763237176.json 2025-11-15 20:06:16.759517  \n",
              "11  bench_hetero_profiled_1763237195.json 2025-11-15 20:06:35.998944  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4832bcc-0032-4103-9178-ff72a457969f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mode</th>\n",
              "      <th>tokens_per_sec</th>\n",
              "      <th>elapsed_sec</th>\n",
              "      <th>blocks_fast</th>\n",
              "      <th>blocks_slow</th>\n",
              "      <th>devices</th>\n",
              "      <th>file</th>\n",
              "      <th>ts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>uniform</td>\n",
              "      <td>13353.957777</td>\n",
              "      <td>4.907609</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>{'fast': 'cuda:0', 'slow': 'cuda:0'}</td>\n",
              "      <td>bench_both_1763237052.json</td>\n",
              "      <td>2025-11-15 20:04:12.917347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>uniform</td>\n",
              "      <td>13284.619482</td>\n",
              "      <td>4.933224</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>{'fast': 'cuda:0', 'slow': 'cuda:0'}</td>\n",
              "      <td>bench_both_1763237076.json</td>\n",
              "      <td>2025-11-15 20:04:36.536093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>hetero</td>\n",
              "      <td>13403.140602</td>\n",
              "      <td>4.889600</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>{'fast': 'cuda:0', 'slow': 'cuda:0'}</td>\n",
              "      <td>bench_both_1763237076.json</td>\n",
              "      <td>2025-11-15 20:04:36.536093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hetero</td>\n",
              "      <td>13062.276376</td>\n",
              "      <td>5.017196</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>{'fast': 'cuda:0', 'slow': 'cuda:0'}</td>\n",
              "      <td>bench_both_1763237100.json</td>\n",
              "      <td>2025-11-15 20:05:00.361854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>uniform</td>\n",
              "      <td>12989.009816</td>\n",
              "      <td>5.045496</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>{'fast': 'cuda:0', 'slow': 'cuda:0'}</td>\n",
              "      <td>bench_both_1763237100.json</td>\n",
              "      <td>2025-11-15 20:05:00.361854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>hetero_profiled</td>\n",
              "      <td>12581.379067</td>\n",
              "      <td>5.208968</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>{'fast': 'cuda:0', 'slow': 'cuda:0'}</td>\n",
              "      <td>bench_hetero_profiled_1763237119.json</td>\n",
              "      <td>2025-11-15 20:05:19.412265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>hetero_profiled</td>\n",
              "      <td>12527.766202</td>\n",
              "      <td>5.231260</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>{'fast': 'cuda:0', 'slow': 'cuda:0'}</td>\n",
              "      <td>bench_hetero_profiled_1763237138.json</td>\n",
              "      <td>2025-11-15 20:05:38.435676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>hetero_profiled</td>\n",
              "      <td>12489.551005</td>\n",
              "      <td>5.247266</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>{'fast': 'cuda:0', 'slow': 'cuda:0'}</td>\n",
              "      <td>bench_hetero_profiled_1763237157.json</td>\n",
              "      <td>2025-11-15 20:05:57.567094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>hetero_profiled</td>\n",
              "      <td>12410.211492</td>\n",
              "      <td>5.280813</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>{'fast': 'cuda:0', 'slow': 'cuda:0'}</td>\n",
              "      <td>bench_hetero_profiled_1763237176.json</td>\n",
              "      <td>2025-11-15 20:06:16.759517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>hetero_profiled</td>\n",
              "      <td>12340.155185</td>\n",
              "      <td>5.310792</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>{'fast': 'cuda:0', 'slow': 'cuda:0'}</td>\n",
              "      <td>bench_hetero_profiled_1763237195.json</td>\n",
              "      <td>2025-11-15 20:06:35.998944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4832bcc-0032-4103-9178-ff72a457969f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4832bcc-0032-4103-9178-ff72a457969f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4832bcc-0032-4103-9178-ff72a457969f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9c49d50a-7639-4a98-8f80-19bfdbe710e6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c49d50a-7639-4a98-8f80-19bfdbe710e6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9c49d50a-7639-4a98-8f80-19bfdbe710e6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"uniform\",\n          \"hetero\",\n          \"hetero_profiled\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens_per_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 417.95167155138154,\n        \"min\": 12340.15518527725,\n        \"max\": 13403.140602102449,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          12410.211492328008,\n          13284.619482452646,\n          12581.379066774778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"elapsed_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16543522997589877,\n        \"min\": 4.8896002769470215,\n        \"max\": 5.3107922077178955,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5.280812501907349,\n          4.933223724365234,\n          5.208967924118042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blocks_fast\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 12,\n        \"max\": 12,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blocks_slow\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 12,\n        \"max\": 12,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"devices\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{'fast': 'cuda:0', 'slow': 'cuda:0'}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"bench_both_1763237076.json\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ts\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-11-15 20:04:12.917347\",\n        \"max\": \"2025-11-15 20:06:35.998944\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"2025-11-15 20:04:36.536093\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "\n",
        "df = pd.read_csv(\"results/summary_all_runs.csv\", parse_dates=[\"ts\"])\n",
        "g = df.groupby(\"mode\")[\"tokens_per_sec\"]\n",
        "summary = pd.DataFrame({\n",
        "    \"runs\": g.count(),\n",
        "    \"mean_tps\": g.mean(),\n",
        "    \"std_tps\": g.std(ddof=1),\n",
        "    \"min_tps\": g.min(),\n",
        "    \"max_tps\": g.max(),\n",
        "}).sort_values(\"mean_tps\", ascending=False)\n",
        "\n",
        "# compare\n",
        "if set([\"uniform\",\"hetero\"]).issubset(summary.index):\n",
        "    uniform = summary.loc[\"uniform\",\"mean_tps\"]\n",
        "    hetero = summary.loc[\"hetero\",\"mean_tps\"]\n",
        "    gain_hetero_vs_uniform = 100 * (hetero - uniform) / uniform\n",
        "else:\n",
        "    gain_hetero_vs_uniform = np.nan\n",
        "\n",
        "if set([\"hetero\",\"hetero_profiled\"]).issubset(summary.index):\n",
        "    hetero = summary.loc[\"hetero\",\"mean_tps\"]\n",
        "    prof   = summary.loc[\"hetero_profiled\",\"mean_tps\"]\n",
        "    gain_profiled_vs_hetero = 100 * (prof - hetero) / hetero\n",
        "else:\n",
        "    gain_profiled_vs_hetero = np.nan\n",
        "\n",
        "print(summary.round(2))\n",
        "print(f\"\\nΔ hetero vs uniform: {gain_hetero_vs_uniform:.2f}%\")\n",
        "print(f\"Δ hetero_profiled vs hetero: {gain_profiled_vs_hetero:.2f}%\")\n",
        "\n",
        "# Save a clean table for slides\n",
        "summary.round(2).to_csv(\"results/summary_stats.csv\")\n",
        "print(\"Saved: results/summary_stats.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meAYTmh4IaXO",
        "outputId": "5ef03416-39f3-492c-f24f-89953bde2f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 runs  mean_tps  std_tps   min_tps   max_tps\n",
            "mode                                                        \n",
            "hetero              6  13694.88   419.57  13062.28  14139.78\n",
            "uniform             6  13494.35   341.82  12989.01  13876.25\n",
            "hetero_profiled     6  12666.90   490.29  12340.16  13652.36\n",
            "\n",
            "Δ hetero vs uniform: 1.49%\n",
            "Δ hetero_profiled vs hetero: -7.51%\n",
            "Saved: results/summary_stats.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A: Uniform vs Hetero\n",
        "!python scripts/plot_results.py results --modes uniform hetero --out results/tps_uniform_vs_hetero.png\n",
        "\n",
        "# B: Hetero Profiled only\n",
        "!python scripts/plot_results.py results --modes hetero_profiled --out results/tps_hetero_profiled.png\n",
        "\n",
        "# C: All three together\n",
        "!python scripts/plot_results.py results --modes uniform hetero hetero_profiled --out results/tpsall_modes.png\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_g4q1JiIhHm",
        "outputId": "d4b4875b-5355-4ce3-ddd2-0b9fef273fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Latest results:\n",
            "- uniform         | tokens/s: 12989.01\n",
            "- hetero          | tokens/s: 13062.28\n",
            "Saved: results/tps_uniform_vs_hetero.png\n",
            "\n",
            "Latest results:\n",
            "- hetero_profiled | tokens/s: 12340.16\n",
            "Saved: results/tps_hetero_profiled.png\n",
            "\n",
            "Latest results:\n",
            "- uniform         | tokens/s: 12989.01\n",
            "- hetero          | tokens/s: 13062.28\n",
            "- hetero_profiled | tokens/s: 12340.16\n",
            "Saved: results/tpsall_modes.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "summary = pd.read_csv(\"results/summary_stats.csv\", index_col=0)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(summary.index, summary[\"mean_tps\"], yerr=summary[\"std_tps\"], capsize=4)\n",
        "plt.ylabel(\"Tokens/sec\")\n",
        "plt.title(\"Throughput (mean ± std) by mode\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"results/tps_mean_std.png\", dpi=200)\n",
        "print(\"Saved: results/tps_mean_std.png\")\n"
      ],
      "metadata": {
        "id": "dBTv4IHOIoC1",
        "outputId": "3fac2683-8b65-4b3f-be0a-ee053169f04f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: results/tps_mean_std.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8E3Xc-RvIqZF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}